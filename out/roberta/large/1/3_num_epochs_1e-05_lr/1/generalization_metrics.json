{
    "anli": {
        "accuracy": 31.6875,
        "accuracy_r1_test": 46.0,
        "accuracy_r2_test": 26.2,
        "accuracy_r3_test": 24.333333333333332,
        "num_correct": 1014,
        "r1_test_correct": 460,
        "r1_test_total": 1000,
        "r2_test_correct": 262,
        "r2_test_total": 1000,
        "r3_test_correct": 292,
        "r3_test_total": 1200,
        "total": 3200
    },
    "bizarro": {
        "accuracy": 76.4375,
        "accuracy_raw_data/bizarro/revised_hypothesis": 83.75,
        "accuracy_raw_data/bizarro/revised_premise": 69.125,
        "num_correct": 1223,
        "raw_data/bizarro/revised_hypothesis_correct": 670,
        "raw_data/bizarro/revised_hypothesis_total": 800,
        "raw_data/bizarro/revised_premise_correct": 553,
        "raw_data/bizarro/revised_premise_total": 800,
        "total": 1600
    },
    "hans": {
        "accuracy": 79.04666666666667,
        "accuracy_constituent_entailment": 99.34,
        "accuracy_constituent_not_entailment": 39.64,
        "accuracy_lexical_overlap_entailment": 99.98,
        "accuracy_lexical_overlap_not_entailment": 96.48,
        "accuracy_subsequence_entailment": 100.0,
        "accuracy_subsequence_not_entailment": 38.84,
        "constituent_entailment_correct": 4967,
        "constituent_entailment_total": 5000,
        "constituent_not_entailment_correct": 1982,
        "constituent_not_entailment_total": 5000,
        "lexical_overlap_entailment_correct": 4999,
        "lexical_overlap_entailment_total": 5000,
        "lexical_overlap_not_entailment_correct": 4824,
        "lexical_overlap_not_entailment_total": 5000,
        "num_correct": 23714,
        "subsequence_entailment_correct": 5000,
        "subsequence_entailment_total": 5000,
        "subsequence_not_entailment_correct": 1942,
        "subsequence_not_entailment_total": 5000,
        "total": 30000
    },
    "mnli_dev": {
        "accuracy": 90.71828833418238,
        "num_correct": 8904,
        "total": 9815
    },
    "rte": {
        "accuracy": 86.84495843874232,
        "accuracy_dev": 86.28158844765343,
        "accuracy_train": 86.90763052208835,
        "dev_correct": 239,
        "dev_total": 277,
        "num_correct": 2403,
        "total": 2767,
        "train_correct": 2164,
        "train_total": 2490
    },
    "scitail": {
        "accuracy": 82.31420507996238,
        "num_correct": 1750,
        "total": 2126
    }
}