{
    "anli": {
        "accuracy": 33.125,
        "accuracy_r1_test": 44.4,
        "accuracy_r2_test": 29.9,
        "accuracy_r3_test": 26.416666666666668,
        "num_correct": 1060,
        "r1_test_correct": 444,
        "r1_test_total": 1000,
        "r2_test_correct": 299,
        "r2_test_total": 1000,
        "r3_test_correct": 317,
        "r3_test_total": 1200,
        "total": 3200
    },
    "bizarro": {
        "accuracy": 75.125,
        "accuracy_raw_data/bizarro/revised_hypothesis": 82.875,
        "accuracy_raw_data/bizarro/revised_premise": 67.375,
        "num_correct": 1202,
        "raw_data/bizarro/revised_hypothesis_correct": 663,
        "raw_data/bizarro/revised_hypothesis_total": 800,
        "raw_data/bizarro/revised_premise_correct": 539,
        "raw_data/bizarro/revised_premise_total": 800,
        "total": 1600
    },
    "hans": {
        "accuracy": 72.02666666666667,
        "accuracy_constituent_entailment": 99.56,
        "accuracy_constituent_not_entailment": 15.9,
        "accuracy_lexical_overlap_entailment": 99.98,
        "accuracy_lexical_overlap_not_entailment": 81.96,
        "accuracy_subsequence_entailment": 100.0,
        "accuracy_subsequence_not_entailment": 34.76,
        "constituent_entailment_correct": 4978,
        "constituent_entailment_total": 5000,
        "constituent_not_entailment_correct": 795,
        "constituent_not_entailment_total": 5000,
        "lexical_overlap_entailment_correct": 4999,
        "lexical_overlap_entailment_total": 5000,
        "lexical_overlap_not_entailment_correct": 4098,
        "lexical_overlap_not_entailment_total": 5000,
        "num_correct": 21608,
        "subsequence_entailment_correct": 5000,
        "subsequence_entailment_total": 5000,
        "subsequence_not_entailment_correct": 1738,
        "subsequence_not_entailment_total": 5000,
        "total": 30000
    },
    "mnli_dev": {
        "accuracy": 90.55527254202751,
        "num_correct": 8888,
        "total": 9815
    },
    "rte": {
        "accuracy": 85.36320925189736,
        "accuracy_dev": 85.92057761732852,
        "accuracy_train": 85.3012048192771,
        "dev_correct": 238,
        "dev_total": 277,
        "num_correct": 2362,
        "total": 2767,
        "train_correct": 2124,
        "train_total": 2490
    },
    "scitail": {
        "accuracy": 83.11382878645344,
        "num_correct": 1767,
        "total": 2126
    }
}