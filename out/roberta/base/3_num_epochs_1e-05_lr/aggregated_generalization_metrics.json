{
    "anli": {
        "accuracy": "27.7 +- 0.7",
        "accuracy_r1_test": "29.3 +- 1.6",
        "accuracy_r2_test": "25.8 +- 0.4",
        "accuracy_r3_test": "27.9 +- 0.5"
    },
    "bizarro": {
        "accuracy": "71.5 +- 0.5",
        "accuracy_raw_data/bizarro/revised_hypothesis": "79.7 +- 0.6",
        "accuracy_raw_data/bizarro/revised_premise": "63.3 +- 0.4"
    },
    "hans": {
        "accuracy": "70.2 +- 2.1",
        "accuracy_constituent_entailment": "98.2 +- 0.2",
        "accuracy_constituent_not_entailment": "33.3 +- 3.3",
        "accuracy_lexical_overlap_entailment": "98.5 +- 0.2",
        "accuracy_lexical_overlap_not_entailment": "64.3 +- 6.4",
        "accuracy_subsequence_entailment": "99.8 +- 0.2",
        "accuracy_subsequence_not_entailment": "27.0 +- 3.6"
    },
    "mnli_dev": {
        "accuracy": "87.7 +- 0.1"
    },
    "rte": {
        "accuracy": "80.6 +- 0.8",
        "accuracy_dev": "79.3 +- 1.3",
        "accuracy_train": "80.7 +- 0.8"
    },
    "scitail": {
        "accuracy": "79.3 +- 0.3"
    }
}