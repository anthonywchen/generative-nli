{
    "anli": {
        "accuracy": 28.03125,
        "accuracy_r1_test": 30.6,
        "accuracy_r2_test": 25.9,
        "accuracy_r3_test": 27.666666666666668,
        "num_correct": 897,
        "r1_test_correct": 306,
        "r1_test_total": 1000,
        "r2_test_correct": 259,
        "r2_test_total": 1000,
        "r3_test_correct": 332,
        "r3_test_total": 1200,
        "total": 3200
    },
    "bizarro": {
        "accuracy": 72.0625,
        "accuracy_raw_data/bizarro/revised_hypothesis": 80.375,
        "accuracy_raw_data/bizarro/revised_premise": 63.75,
        "num_correct": 1153,
        "raw_data/bizarro/revised_hypothesis_correct": 643,
        "raw_data/bizarro/revised_hypothesis_total": 800,
        "raw_data/bizarro/revised_premise_correct": 510,
        "raw_data/bizarro/revised_premise_total": 800,
        "total": 1600
    },
    "hans": {
        "accuracy": 72.24,
        "accuracy_constituent_entailment": 98.16,
        "accuracy_constituent_not_entailment": 37.04,
        "accuracy_lexical_overlap_entailment": 98.44,
        "accuracy_lexical_overlap_not_entailment": 69.28,
        "accuracy_subsequence_entailment": 99.78,
        "accuracy_subsequence_not_entailment": 30.74,
        "constituent_entailment_correct": 4908,
        "constituent_entailment_total": 5000,
        "constituent_not_entailment_correct": 1852,
        "constituent_not_entailment_total": 5000,
        "lexical_overlap_entailment_correct": 4922,
        "lexical_overlap_entailment_total": 5000,
        "lexical_overlap_not_entailment_correct": 3464,
        "lexical_overlap_not_entailment_total": 5000,
        "num_correct": 21672,
        "subsequence_entailment_correct": 4989,
        "subsequence_entailment_total": 5000,
        "subsequence_not_entailment_correct": 1537,
        "subsequence_not_entailment_total": 5000,
        "total": 30000
    },
    "mnli_dev": {
        "accuracy": 87.6413652572593,
        "num_correct": 8602,
        "total": 9815
    },
    "rte": {
        "accuracy": 81.02638236357065,
        "accuracy_dev": 80.50541516245487,
        "accuracy_train": 81.08433734939759,
        "dev_correct": 223,
        "dev_total": 277,
        "num_correct": 2242,
        "total": 2767,
        "train_correct": 2019,
        "train_total": 2490
    },
    "scitail": {
        "accuracy": 79.35089369708372,
        "num_correct": 1687,
        "total": 2126
    }
}