{
    "anli": {
        "accuracy": 27.46875,
        "accuracy_r1_test": 29.6,
        "accuracy_r2_test": 25.4,
        "accuracy_r3_test": 27.416666666666668,
        "num_correct": 879,
        "r1_test_correct": 296,
        "r1_test_total": 1000,
        "r2_test_correct": 254,
        "r2_test_total": 1000,
        "r3_test_correct": 329,
        "r3_test_total": 1200,
        "total": 3200
    },
    "bizarro": {
        "accuracy": 71.25,
        "accuracy_raw_data/bizarro/revised_hypothesis": 80.125,
        "accuracy_raw_data/bizarro/revised_premise": 62.375,
        "num_correct": 1140,
        "raw_data/bizarro/revised_hypothesis_correct": 641,
        "raw_data/bizarro/revised_hypothesis_total": 800,
        "raw_data/bizarro/revised_premise_correct": 499,
        "raw_data/bizarro/revised_premise_total": 800,
        "total": 1600
    },
    "hans": {
        "accuracy": 72.44333333333333,
        "accuracy_constituent_entailment": 98.1,
        "accuracy_constituent_not_entailment": 37.42,
        "accuracy_lexical_overlap_entailment": 97.58,
        "accuracy_lexical_overlap_not_entailment": 68.74,
        "accuracy_subsequence_entailment": 99.72,
        "accuracy_subsequence_not_entailment": 33.1,
        "constituent_entailment_correct": 4905,
        "constituent_entailment_total": 5000,
        "constituent_not_entailment_correct": 1871,
        "constituent_not_entailment_total": 5000,
        "lexical_overlap_entailment_correct": 4879,
        "lexical_overlap_entailment_total": 5000,
        "lexical_overlap_not_entailment_correct": 3437,
        "lexical_overlap_not_entailment_total": 5000,
        "num_correct": 21733,
        "subsequence_entailment_correct": 4986,
        "subsequence_entailment_total": 5000,
        "subsequence_not_entailment_correct": 1655,
        "subsequence_not_entailment_total": 5000,
        "total": 30000
    },
    "mnli": {
        "accuracy": 87.8858889454916,
        "num_correct": 8626,
        "total": 9815
    },
    "rte": {
        "accuracy": 81.09866281170943,
        "accuracy_dev": 79.42238267148015,
        "accuracy_train": 81.285140562249,
        "dev_correct": 220,
        "dev_total": 277,
        "num_correct": 2244,
        "total": 2767,
        "train_correct": 2024,
        "train_total": 2490
    },
    "scitail": {
        "accuracy": 80.05644402634054,
        "num_correct": 1702,
        "total": 2126
    }
}