{
    "anli": {
        "accuracy": 26.84375,
        "accuracy_r1_test": 22.9,
        "accuracy_r2_test": 28.3,
        "accuracy_r3_test": 28.916666666666668,
        "num_correct": 859,
        "r1_test_correct": 229,
        "r1_test_total": 1000,
        "r2_test_correct": 283,
        "r2_test_total": 1000,
        "r3_test_correct": 347,
        "r3_test_total": 1200,
        "total": 3200
    },
    "bizarro": {
        "accuracy": 67.8125,
        "accuracy_raw_data/bizarro/revised_hypothesis": 75.25,
        "accuracy_raw_data/bizarro/revised_premise": 60.375,
        "num_correct": 1085,
        "raw_data/bizarro/revised_hypothesis_correct": 602,
        "raw_data/bizarro/revised_hypothesis_total": 800,
        "raw_data/bizarro/revised_premise_correct": 483,
        "raw_data/bizarro/revised_premise_total": 800,
        "total": 1600
    },
    "hans": {
        "accuracy": 58.223333333333336,
        "accuracy_constituent_entailment": 98.18,
        "accuracy_constituent_not_entailment": 21.84,
        "accuracy_lexical_overlap_entailment": 96.64,
        "accuracy_lexical_overlap_not_entailment": 28.4,
        "accuracy_subsequence_entailment": 99.58,
        "accuracy_subsequence_not_entailment": 4.7,
        "constituent_entailment_correct": 4909,
        "constituent_entailment_total": 5000,
        "constituent_not_entailment_correct": 1092,
        "constituent_not_entailment_total": 5000,
        "lexical_overlap_entailment_correct": 4832,
        "lexical_overlap_entailment_total": 5000,
        "lexical_overlap_not_entailment_correct": 1420,
        "lexical_overlap_not_entailment_total": 5000,
        "num_correct": 17467,
        "subsequence_entailment_correct": 4979,
        "subsequence_entailment_total": 5000,
        "subsequence_not_entailment_correct": 235,
        "subsequence_not_entailment_total": 5000,
        "total": 30000
    },
    "mnli_dev": {
        "accuracy": 84.72745797249108,
        "num_correct": 8316,
        "total": 9815
    },
    "rte": {
        "accuracy": 75.4969280809541,
        "accuracy_dev": 73.64620938628158,
        "accuracy_train": 75.70281124497993,
        "dev_correct": 204,
        "dev_total": 277,
        "num_correct": 2089,
        "total": 2767,
        "train_correct": 1885,
        "train_total": 2490
    },
    "scitail": {
        "accuracy": 78.78645343367828,
        "num_correct": 1675,
        "total": 2126
    }
}