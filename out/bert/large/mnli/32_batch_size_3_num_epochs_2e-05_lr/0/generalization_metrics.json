{
    "anli": {
        "accuracy": 26.78125,
        "accuracy_r1_test": 21.2,
        "accuracy_r2_test": 29.4,
        "accuracy_r3_test": 29.25,
        "num_correct": 857,
        "r1_test_correct": 212,
        "r1_test_total": 1000,
        "r2_test_correct": 294,
        "r2_test_total": 1000,
        "r3_test_correct": 351,
        "r3_test_total": 1200,
        "total": 3200
    },
    "bizarro": {
        "accuracy": 71.625,
        "accuracy_raw_data/bizarro/revised_hypothesis": 79.375,
        "accuracy_raw_data/bizarro/revised_premise": 63.875,
        "num_correct": 1146,
        "raw_data/bizarro/revised_hypothesis_correct": 635,
        "raw_data/bizarro/revised_hypothesis_total": 800,
        "raw_data/bizarro/revised_premise_correct": 511,
        "raw_data/bizarro/revised_premise_total": 800,
        "total": 1600
    },
    "hans": {
        "accuracy": 70.56,
        "accuracy_constituent_entailment": 98.9,
        "accuracy_constituent_not_entailment": 35.14,
        "accuracy_lexical_overlap_entailment": 95.24,
        "accuracy_lexical_overlap_not_entailment": 69.44,
        "accuracy_subsequence_entailment": 99.66,
        "accuracy_subsequence_not_entailment": 24.98,
        "constituent_entailment_correct": 4945,
        "constituent_entailment_total": 5000,
        "constituent_not_entailment_correct": 1757,
        "constituent_not_entailment_total": 5000,
        "lexical_overlap_entailment_correct": 4762,
        "lexical_overlap_entailment_total": 5000,
        "lexical_overlap_not_entailment_correct": 3472,
        "lexical_overlap_not_entailment_total": 5000,
        "num_correct": 21168,
        "subsequence_entailment_correct": 4983,
        "subsequence_entailment_total": 5000,
        "subsequence_not_entailment_correct": 1249,
        "subsequence_not_entailment_total": 5000,
        "total": 30000
    },
    "mnli_dev": {
        "accuracy": 86.60213958227203,
        "num_correct": 8500,
        "total": 9815
    },
    "rte": {
        "accuracy": 78.24358511022768,
        "accuracy_dev": 76.17328519855596,
        "accuracy_train": 78.47389558232932,
        "dev_correct": 211,
        "dev_total": 277,
        "num_correct": 2165,
        "total": 2767,
        "train_correct": 1954,
        "train_total": 2490
    },
    "scitail": {
        "accuracy": 81.89087488240828,
        "num_correct": 1741,
        "total": 2126
    }
}