{	
	"random_seed": 42,
	"pytorch_seed": 42,
	"numpy_seed": 42,
	"train_data_path": "data/mnli/train.jsonl" ,
	"validation_data_path": "data/mnli/dev.jsonl" ,
	"datasets_for_vocab_creation": [],
	"dataset_reader": {
		"type": "gnli",
		"pretrained_model": "roberta-large",
		"max_premise_length": 128,
		"max_hypothesis_length": 80,
		"percent_data": 0.001,
	},
	"validation_dataset_reader": {
		"type": "gnli",
		"pretrained_model": "roberta-large",
		"max_premise_length": 128,
		"max_hypothesis_length": 80,
		"percent_data": 0.1,
	},
	"model": {
		"type": "gnli",
		"pretrained_model": "bart.large",
		"discriminative_loss_weight": [1],
	},
	"iterator": {
		"type": "basic",
		"batch_size" : 32,
	},
	"trainer": {
		"type": "apextrainer",
		"cuda_device": 0,
		"num_epochs": [10, 20, 40],
		"patience": 15,
		"half_precision": true,
		"accumulation_steps": 16,
		"opt_level": "O2",
		"num_serialized_models_to_keep": 0,
		"validation_metric": "+accuracy",
		"warmup_proportion": 0.06,
		"optimizer": {
			"type": "adamw",
			"lr": [1e-5, 3e-5],
			"betas": [0.9, 0.98],
			"weight_decay": 0.01,
			"parameter_groups": [
			  [["bias", "LayerNorm.bias", "LayerNorm.weight"], {"weight_decay": 0.0}],
			],
		},
	},
}